[
  {
    "objectID": "nn.html",
    "href": "nn.html",
    "title": "Custom Module and Sequential",
    "section": "",
    "text": "source\n\nHistory\nThis object inherits from base dict to provide a History object similar to Keras’, allowing the automatic logging of the loss and the different metrics during training. It’s automatically used in .fit() (as it is in Keras).\n\nsource\n\n\nModule\n\n Module (**kwargs)\n\nModification of PyTorch base nn.Module to provide a basic predefined training loop with logging and a Keras-like interface to be able to customize the training. This Module implements as well a .compile() method and an .evaluate() one. All is done to obtain a behaviour as similar to Keras as possible.\n\nsource\n\n\nModule.fit\n\n Module.fit (trainloader:torch.utils.data.dataloader.DataLoader, epochs,\n             validationloader=None)\n\nFit a model to the desired trainloader for epochs epochs. Returns the corresponding History.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntrainloader\nDataLoader\n\nTraining DataLoader.\n\n\nepochs\n\n\nNumber of epochs to train.\n\n\nvalidationloader\nNoneType\nNone\nValidation DataLoader (optional).\n\n\nReturns\nHistory\n\nHistory object with the training dynamics as in Keras.\n\n\n\n\nsource\n\n\nModule.compile\n\n Module.compile (loss:Optional=None,\n                 optimizer:Optional[torch.optim.optimizer.Optimizer]=None,\n                 metrics=None)\n\nSets the loss, optimizer and desired metrics to train the model.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nloss\nOptional\nNone\nLoss function to be used.\n\n\noptimizer\nOptional\nNone\nOptimizer to be used.\n\n\nmetrics\nNoneType\nNone\nMetricCollection containing the desired metrics.\n\n\n\n\nsource\n\n\nModule.evaluate\n\n Module.evaluate (dataloader)\n\nEvaluates the model on a set of data.\n\n\n\n\nType\nDetails\n\n\n\n\ndataloader\n\nDataLoader to evaluate the model with.\n\n\nReturns\nDict\nResults from the evaluation\n\n\n\n\n\nExample of usage\nWe can perform a very simple example using the Fashion MNIST dataset (as is done in the official PyTorch docs.\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))])\n\n# Create datasets for training & validation, download if necessary\ntraining_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\nvalidation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n\n# Create data loaders for our datasets; shuffle for training, not for validation\ntraining_loader = torch.utils.data.DataLoader(training_set, batch_size=128, shuffle=True, num_workers=0)\nvalidation_loader = torch.utils.data.DataLoader(validation_set, batch_size=256, shuffle=False, num_workers=0)\n\nSee that the only different with respect to basic PyTorch is that we’re inhereting from our custom Module, not from PyTorch’s nn.Module:\n\nclass SimpleModel(Module):\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nFollowing the usual Keras way, we instantiate the model and compile it, providing the loss and the optimizer:\n\nmodel = SimpleModel()\nmodel.compile(loss=torch.nn.CrossEntropyLoss(),\n              optimizer=torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n              metrics = MetricCollection([Accuracy()]))\n\n\nmodel\n\nSimpleModel(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=256, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n  (loss_fn): CrossEntropyLoss()\n  (metrics): MetricCollection(\n    (Accuracy): Accuracy()\n  )\n)\n\n\n\nmodel.evaluate(training_loader), model.evaluate(validation_loader)\n\n\n\n\n\n\n\n({'Accuracy': 0.11770944386275846, 'Loss': 2.3061464941069514},\n {'Accuracy': 0.12353515625, 'Loss': 2.3057154595851896})\n\n\n\nhistory = model.fit(trainloader=training_loader, epochs=1, validationloader=validation_loader)\n\n\n\n\n\n\n\n\n\n\n\nhistory\n\n{'Accuracy': [0.18737784294939752],\n 'Loss': [2.2949233914235],\n 'Val_Accuracy': [0.2640625],\n 'Val_Loss': [2.2760460674762726]}\n\n\n\nmodel.evaluate(training_loader), model.evaluate(validation_loader)\n\n\n\n\n\n\n\n({'Accuracy': 0.25996690654932564, 'Loss': 2.276174947905388},\n {'Accuracy': 0.2640625, 'Loss': 2.2760460674762726})"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Korch",
    "section": "",
    "text": "pip install korch"
  },
  {
    "objectID": "index.html#example-of-usage",
    "href": "index.html#example-of-usage",
    "title": "Korch",
    "section": "Example of usage",
    "text": "Example of usage\nWe can perform a very simple example using the Fashion MNIST dataset (as is done in the official PyTorch docs.\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))])\n\n# Create datasets for training & validation, download if necessary\ntraining_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\nvalidation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n\n# Create data loaders for our datasets; shuffle for training, not for validation\ntraining_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True, num_workers=0)\nvalidation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False, num_workers=0)\n\nSee that the only different with respect to basic PyTorch is that we’re inhereting from our custom Module, not from PyTorch’s nn.Module:\n\nclass SimpleModel(Module):\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nFollowing the usual Keras way, we instantiate the model and compile it, providing the loss and the optimizer. Metrics can be provided as well, and are expected as torchvision.MetricCollection:\n\nmodel = SimpleModel()\nmodel.compile(loss=torch.nn.CrossEntropyLoss(),\n              optimizer=torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n              metrics = MetricCollection([Accuracy()]))\n\n\nmodel\n\nSimpleModel(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=256, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n  (loss_fn): CrossEntropyLoss()\n)\n\n\n\nmodel.evaluate(training_loader), model.evaluate(validation_loader)\n\n(2.3070596095879874, 2.307082461261749)\n\n\n\nmodel.fit(trainloader=training_loader, epochs=1, validationloader=validation_loader)\n\n\nmodel.evaluate(training_loader), model.evaluate(validation_loader)\n\n(0.39349932589025605, 0.42693415356237674)"
  }
]