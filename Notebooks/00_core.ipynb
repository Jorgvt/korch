{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korch\n",
    "\n",
    "> Simple tools to provide a Keras-like interface to PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy, MetricCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| exporti\n",
    "def get_pbar_description_from_batch_metrics(batch_metrics, prefix=\"\"):\n",
    "    description = \"\"\n",
    "    for name, value in batch_metrics.items():\n",
    "        description += f'{prefix}{name}: {value:.2f} '\n",
    "    return description[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class History(dict):\n",
    "    \"\"\"\n",
    "    This object inherits from base `dict` to provide a `History` object similar to Keras', \n",
    "    allowing the automatic logging of the loss and the different metrics during training. \n",
    "    It's automatically used in `.fit()` (as it is in Keras).\n",
    "    \"\"\"\n",
    "    def log_dict(self, data, prefix=\"\"):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: dict\n",
    "        \"\"\"\n",
    "        for name, value in data.items():\n",
    "            name = prefix+name\n",
    "            if name in self.keys():\n",
    "                self[name].append(value)\n",
    "            else:\n",
    "                self[name] = [value]\n",
    "\n",
    "    def aggregate(self, agg_fn=lambda x: sum(x)/len(x)):\n",
    "        \"\"\"\n",
    "        Aggregates the stored values using the designed aggregation function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        agg_fn: function\n",
    "            Mean by default.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        agg_data: dict\n",
    "            Aggregated data.\n",
    "        \"\"\"\n",
    "        return {name:agg_fn(values) for name, values in self.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Module(nn.Module):\n",
    "    \"\"\"\n",
    "    Modification of PyTorch base `nn.Module` to provide a basic\n",
    "    predefined training loop with logging and a Keras-like interface\n",
    "    to be able to customize the training.\n",
    "    This Module implements as well as a `compile` method and an `evaluate` one. \n",
    "    All is done to obtain a behaviour as similar to Keras as possible.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Module, self).__init__(**kwargs)\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        inputs, labels = batch\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        ## Obtain metrics if needed\n",
    "        if self.metrics is not None:\n",
    "            metrics = self.metrics(outputs, labels)\n",
    "            metrics = {name:value.item() for name, value in metrics.items()}\n",
    "            metrics['Loss'] = loss.item()\n",
    "        else:\n",
    "            metrics = {'Loss':loss.item()}\n",
    "        return metrics\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "        ## Obtain metrics if needed\n",
    "        if self.metrics is not None:\n",
    "            metrics = self.metrics(outputs, labels)\n",
    "            metrics = {name:value.item() for name, value in metrics.items()}\n",
    "            metrics['Loss'] = loss.item()\n",
    "        else:\n",
    "            metrics = {'Loss':loss.item()}\n",
    "        return metrics\n",
    "\n",
    "    def fit(self, trainloader, epochs, validationloader=None):\n",
    "        history_epoch = History()\n",
    "        for epoch in tqdm(range(epochs), desc='Epochs', position=0):\n",
    "            self.train()\n",
    "            pbar = tqdm(enumerate(trainloader), total=len(trainloader), position=1, leave=False)\n",
    "            history_batch = History()\n",
    "            for batch_idx, batch in pbar:\n",
    "                batch_metrics = self.train_step(batch)\n",
    "                history_batch.log_dict(batch_metrics)\n",
    "                pbar.set_description(get_pbar_description_from_batch_metrics(batch_metrics))\n",
    "            if validationloader is not None:\n",
    "                self.eval()\n",
    "                pbar = tqdm(enumerate(validationloader), total=len(validationloader), position=2, leave=False)\n",
    "                for batch_idx, batch in pbar:\n",
    "                    with torch.no_grad():\n",
    "                        batch_metrics = self.validation_step(batch)\n",
    "                    history_batch.log_dict(batch_metrics, prefix='Val_')\n",
    "                    pbar.set_description(get_pbar_description_from_batch_metrics(batch_metrics, 'Val_'))\n",
    "            self.metrics.reset()\n",
    "            history_epoch.log_dict(history_batch.aggregate())\n",
    "        return history_epoch\n",
    "\n",
    "    def compile(self, loss=None, optimizer=None, metrics=None):\n",
    "        \"\"\"\n",
    "        metrics: torchmetrics.MetricCollection\n",
    "        \"\"\"\n",
    "        self.loss_fn = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics = metrics\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.eval()\n",
    "        for i, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            if i == 0:\n",
    "                results = self.validation_step(batch)\n",
    "                results = {name:[value] for name, value in results.items()}\n",
    "            else:\n",
    "                result = self.validation_step(batch)\n",
    "                for name, value in result.items():\n",
    "                    results[name].append(value)\n",
    "        results = {name:sum(values)/len(values) for name,values in results.items()}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a very simple example using the Fashion MNIST dataset (as is done in the official [PyTorch docs](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6de7d92b44d4dccab415f4a68b6d62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313993b11d264b558898a87a4821d30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd68b2e4df34beabd61b89488a436bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d843f0486364930a4ec8134da3d63a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=256, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that the only different with respect to basic PyTorch is that we're inhereting from our custom `Module`, not from PyTorch's `nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the usual Keras way, we instantiate the model and compile it, providing the *loss* and the *optimizer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel()\n",
    "model.compile(loss=torch.nn.CrossEntropyLoss(),\n",
    "              optimizer=torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "              metrics = MetricCollection([Accuracy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (metrics): MetricCollection(\n",
       "    (Accuracy): Accuracy()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e9f50b80e040cdaca1486538dccd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82325361ce7542d6aaaf6373300083ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.1635905294847895, 'Loss': 2.3032673564292727},\n",
       " {'Accuracy': 0.15712890625, 'Loss': 2.3037723541259765})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_loader), model.evaluate(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7360a6de8b8e40e0906f4451063769dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42eeab7dca6b408d95fbd4124f4227c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880133bd0a2c47b99a94f4b3cf9b0035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(trainloader=training_loader, epochs=1, validationloader=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': [0.19986007462686567],\n",
       " 'Loss': [2.274188762534656],\n",
       " 'Val_Accuracy': [0.390625],\n",
       " 'Val_Loss': [2.169258713722229]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459cf71a03fc48128290d4ae5c1d24ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4319f9d8b42b4dc29d416e313b6214f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.389570007128502, 'Loss': 2.1693943116202283},\n",
       " {'Accuracy': 0.390625, 'Loss': 2.169258713722229})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_loader), model.evaluate(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpu')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
