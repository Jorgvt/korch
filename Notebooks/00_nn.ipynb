{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom `Module` and `Sequential`\n",
    "\n",
    "> Simple tools to provide a Keras-like interface to PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy, MetricCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Dict, Callable, Optional\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def get_pbar_description_from_batch_metrics(batch_metrics, prefix=\"\"):\n",
    "    description = \"\"\n",
    "    for name, value in batch_metrics.items():\n",
    "        description += f'{prefix}{name}: {value:.2f} '\n",
    "    return description[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class History(dict):\n",
    "    \"\"\"\n",
    "    This object inherits from base `dict` to provide a `History` object similar to Keras', \n",
    "    allowing the automatic logging of the loss and the different metrics during training. \n",
    "    It's automatically used in `.fit()` (as it is in Keras).\n",
    "    \"\"\"\n",
    "    def log_dict(self, \n",
    "                 data: Dict, # Dictionary to log.\n",
    "                 prefix=\"\", # Prefix for the logged metrics.\n",
    "                 ):\n",
    "        \"\"\"Logs a dictionary into the `History` object.\"\"\"\n",
    "        for name, value in data.items():\n",
    "            name = prefix+name\n",
    "            if name in self.keys():\n",
    "                self[name].append(value)\n",
    "            else:\n",
    "                self[name] = [value]\n",
    "\n",
    "    def aggregate(self, \n",
    "                  agg_fn: Callable = lambda x: sum(x)/len(x), # Function used to aggregate the data.\n",
    "                  ) -> Dict: # Returns a dictionary with the aggregated data.\n",
    "        \"\"\"Aggregates the stored values using the designed aggregation function.\"\"\"\n",
    "        return {name:agg_fn(values) for name, values in self.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Module(nn.Module):\n",
    "    \"\"\"\n",
    "    Modification of PyTorch base `nn.Module` to provide a basic\n",
    "    predefined training loop with logging and a Keras-like interface\n",
    "    to be able to customize the training.\n",
    "    This Module implements as well a `.compile()` method and an `.evaluate()` one. \n",
    "    All is done to obtain a behaviour as similar to Keras as possible.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Module, self).__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@patch\n",
    "def train_step(self: Module, \n",
    "               batch, # Batch of data to train.\n",
    "               ) -> Dict: # Metrics from the training step.\n",
    "    \"\"\"Perform a training step.\"\"\"\n",
    "\n",
    "    inputs, labels = batch\n",
    "    self.optimizer.zero_grad()\n",
    "    outputs = self(inputs)\n",
    "    loss = self.loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "\n",
    "    ## Obtain metrics if needed\n",
    "    if self.metrics is not None:\n",
    "        metrics = self.metrics(outputs, labels)\n",
    "        metrics = {name:value.item() for name, value in metrics.items()}\n",
    "        metrics['Loss'] = loss.item()\n",
    "    else:\n",
    "        metrics = {'Loss':loss.item()}\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|Â exporti\n",
    "@patch\n",
    "def validation_step(self: Module, \n",
    "                    batch, # Batch of data to validate.\n",
    "                    ) -> Dict: # Metrics from the validation step.\n",
    "    \"\"\"Perform a validation step\"\"\"\n",
    "\n",
    "    inputs, labels = batch\n",
    "    outputs = self(inputs)\n",
    "    loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "    ## Obtain metrics if needed\n",
    "    if self.metrics is not None:\n",
    "        metrics = self.metrics(outputs, labels)\n",
    "        metrics = {name:value.item() for name, value in metrics.items()}\n",
    "        metrics['Loss'] = loss.item()\n",
    "    else:\n",
    "        metrics = {'Loss':loss.item()}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def fit(self: Module, \n",
    "        trainloader: torch.utils.data.DataLoader, # Training DataLoader. \n",
    "        epochs, # Number of epochs to train.\n",
    "        validationloader=None, # Validation DataLoader (optional).\n",
    "        ) -> History: # History object with the training dynamics as in Keras.\n",
    "    \"\"\"Fit a model to the desired `trainloader` for `epochs` epochs. Returns the corresponding `History`.\"\"\"\n",
    "\n",
    "    history_epoch = History()\n",
    "    for epoch in tqdm(range(epochs), desc='Epochs', position=0):\n",
    "        self.train()\n",
    "        pbar = tqdm(enumerate(trainloader), total=len(trainloader), position=1, leave=False)\n",
    "        history_batch = History()\n",
    "        for batch_idx, batch in pbar:\n",
    "            batch_metrics = self.train_step(batch)\n",
    "            history_batch.log_dict(batch_metrics)\n",
    "            pbar.set_description(get_pbar_description_from_batch_metrics(batch_metrics))\n",
    "        if validationloader is not None:\n",
    "            self.eval()\n",
    "            pbar = tqdm(enumerate(validationloader), total=len(validationloader), position=2, leave=False)\n",
    "            for batch_idx, batch in pbar:\n",
    "                with torch.no_grad():\n",
    "                    batch_metrics = self.validation_step(batch)\n",
    "                history_batch.log_dict(batch_metrics, prefix='Val_')\n",
    "                pbar.set_description(get_pbar_description_from_batch_metrics(batch_metrics, 'Val_'))\n",
    "        self.metrics.reset()\n",
    "        history_epoch.log_dict(history_batch.aggregate())\n",
    "    return history_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def compile(self: Module, \n",
    "            loss: Optional=None, # Loss function to be used.\n",
    "            optimizer: Optional[torch.optim.Optimizer] = None, # Optimizer to be used.\n",
    "            metrics=None, # `MetricCollection` containing the desired metrics.\n",
    "            ):\n",
    "    \"\"\"Sets the loss, optimizer and desired metrics to train the model.\"\"\"\n",
    "\n",
    "    self.loss_fn = loss\n",
    "    self.optimizer = optimizer\n",
    "    self.metrics = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def evaluate(self: Module, \n",
    "             dataloader, # `DataLoader` to evaluate the model with.\n",
    "             ) -> Dict: # Results from the evaluation\n",
    "    \"\"\"Evaluates the model on a set of data.\"\"\"\n",
    "\n",
    "    self.eval()\n",
    "    for i, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        if i == 0:\n",
    "            results = self.validation_step(batch)\n",
    "            results = {name:[value] for name, value in results.items()}\n",
    "        else:\n",
    "            result = self.validation_step(batch)\n",
    "            for name, value in result.items():\n",
    "                results[name].append(value)\n",
    "    results = {name:sum(values)/len(values) for name,values in results.items()}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a very simple example using the Fashion MNIST dataset (as is done in the official [PyTorch docs](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=128, shuffle=True, num_workers=0)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=256, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that the only different with respect to basic PyTorch is that we're inhereting from our custom `Module`, not from PyTorch's `nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the usual Keras way, we instantiate the model and compile it, providing the *loss* and the *optimizer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel()\n",
    "model.compile(loss=torch.nn.CrossEntropyLoss(),\n",
    "              optimizer=torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "              metrics = MetricCollection([Accuracy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (metrics): MetricCollection(\n",
       "    (Accuracy): Accuracy()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a0d9fc3bbb4737acd916fd15d46d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2c01fafec54b3c811cbc7112422ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.11770944386275846, 'Loss': 2.3061464941069514},\n",
       " {'Accuracy': 0.12353515625, 'Loss': 2.3057154595851896})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_loader), model.evaluate(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3035efc3164f0392da3e20a08bfc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4f5c6cd3a9431fbe3889d1d7ed0fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3912cc225ec64d07a5e148b420e89575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(trainloader=training_loader, epochs=1, validationloader=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': [0.18737784294939752],\n",
       " 'Loss': [2.2949233914235],\n",
       " 'Val_Accuracy': [0.2640625],\n",
       " 'Val_Loss': [2.2760460674762726]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9792f6fe100f461ab84888cecc3db011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955c1f4ede26467db9272ff7ac23bf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.25996690654932564, 'Loss': 2.276174947905388},\n",
       " {'Accuracy': 0.2640625, 'Loss': 2.2760460674762726})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_loader), model.evaluate(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpu')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
