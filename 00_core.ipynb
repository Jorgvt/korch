{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korch\n",
    "\n",
    "> Simple tools to provide a Keras-like interface to PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy, MetricCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#exporti\n",
    "def get_pbar_description_from_batch_metrics(batch_metrics, prefix=\"\"):\n",
    "    description = \"\"\n",
    "    for name, value in batch_metrics.items():\n",
    "        description += f'{prefix}{name}: {value:.2f} '\n",
    "    return description[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class History(dict):\n",
    "    def log_dict(self, data, prefix=\"\"):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: dict\n",
    "        \"\"\"\n",
    "        for name, value in data.items():\n",
    "            name = prefix+name\n",
    "            if name in self.keys():\n",
    "                self[name].append(value)\n",
    "            else:\n",
    "                self[name] = [value]\n",
    "\n",
    "    def aggregate(self, agg_fn=lambda x: sum(x)/len(x)):\n",
    "        \"\"\"\n",
    "        Aggregates the stored values using the designed aggregation function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        agg_fn: function\n",
    "            Mean by default.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        agg_data: dict\n",
    "            Aggregated data.\n",
    "        \"\"\"\n",
    "        return {name:agg_fn(values) for name, values in self.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object inherits from base `dict` to provide a `History` object similar to Keras', allowing the automatic logging of the loss and the different metrics during training. Is automatically used in `.fit()` (as it is in Keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Module(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Module, self).__init__(**kwargs)\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        inputs, labels = batch\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        ## Obtain metrics if needed\n",
    "        if self.metrics is not None:\n",
    "            metrics = self.metrics(outputs, labels)\n",
    "            metrics = {name:value.item() for name, value in metrics.items()}\n",
    "            metrics['Loss'] = loss.item()\n",
    "        else:\n",
    "            metrics = {'Loss':loss.item()}\n",
    "        return metrics\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "        ## Obtain metrics if needed\n",
    "        if self.metrics is not None:\n",
    "            metrics = self.metrics(outputs, labels)\n",
    "            metrics = {name:value.item() for name, value in metrics.items()}\n",
    "            metrics['Loss'] = loss.item()\n",
    "        else:\n",
    "            metrics = {'Loss':loss.item()}\n",
    "        return metrics\n",
    "\n",
    "    def fit(self, trainloader, epochs, validationloader=None):\n",
    "        history_epoch = History()\n",
    "        for epoch in tqdm(range(epochs), desc='Epochs', position=0):\n",
    "            self.train()\n",
    "            pbar = tqdm(enumerate(trainloader), total=len(trainloader), position=1, leave=False)\n",
    "            history_batch = History()\n",
    "            for batch_idx, batch in pbar:\n",
    "                batch_metrics = self.train_step(batch)\n",
    "                history_batch.log_dict(batch_metrics)\n",
    "                pbar.set_description(get_pbar_description_from_batch_metrics(batch_metrics))\n",
    "            if validationloader is not None:\n",
    "                self.eval()\n",
    "                pbar = tqdm(enumerate(validationloader), total=len(validationloader), position=2, leave=False)\n",
    "                for batch_idx, batch in pbar:\n",
    "                    with torch.no_grad():\n",
    "                        batch_metrics = self.validation_step(batch)\n",
    "                    history_batch.log_dict(batch_metrics, prefix='Val_')\n",
    "                    pbar.set_description(get_pbar_description_from_batch_metrics(batch_metrics, 'Val_'))\n",
    "            self.metrics.reset()\n",
    "            history_epoch.log_dict(history_batch.aggregate())\n",
    "        return history_epoch\n",
    "\n",
    "    def compile(self, loss=None, optimizer=None, metrics=None):\n",
    "        \"\"\"\n",
    "        metrics: torchmetrics.MetricCollection\n",
    "        \"\"\"\n",
    "        self.loss_fn = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.metrics = metrics\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.eval()\n",
    "        for i, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            if i == 0:\n",
    "                results = self.validation_step(batch)\n",
    "                results = {name:[value] for name, value in results.items()}\n",
    "            else:\n",
    "                result = self.validation_step(batch)\n",
    "                for name, value in result.items():\n",
    "                    results[name].append(value)\n",
    "        results = {name:sum(values)/len(values) for name,values in results.items()}\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Module implements a basic training loop similar to Keras', as well as a `compile` method and an `evaluate` one. All is done to obtain a behaviour as similar to Keras as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a very simple example using the Fashion MNIST dataset (as is done in the official [PyTorch docs](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=256, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that the only different with respect to basic PyTorch is that we're inhereting from our custom `Module`, not from PyTorch's `nn.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the usual Keras way, we instantiate the model and compile it, providing the *loss* and the *optimizer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel()\n",
    "model.compile(loss=torch.nn.CrossEntropyLoss(),\n",
    "              optimizer=torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "              metrics = MetricCollection([Accuracy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (metrics): MetricCollection(\n",
       "    (Accuracy): Accuracy()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee71d8bb92854e38b687c38b8a3d3da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51ba1464b354e65b20007b02b6cea4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.10011327292110875, 'Loss': 2.3076691297071577},\n",
       " {'Accuracy': 0.09892578125, 'Loss': 2.3078657686710358})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_loader), model.evaluate(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323406fbdfc64c5d861d540c15997285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55839b6e546d49318df63259c28da63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92020480092c43ab8629f9598dd4c5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(trainloader=training_loader, epochs=1, validationloader=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': [0.17958200073191352],\n",
       " 'Loss': [2.293788175338875],\n",
       " 'Val_Accuracy': [0.36142578125],\n",
       " 'Val_Loss': [2.26760156750679]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b2fbb137a547fba47574d46d0dc8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9ec64e35ba4bde8edfacfd026ec7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.35581578711456835, 'Loss': 2.2677379803362685},\n",
       " {'Accuracy': 0.36142578125, 'Loss': 2.26760156750679})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(training_loader), model.evaluate(validation_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
